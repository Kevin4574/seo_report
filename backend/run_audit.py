#!/usr/bin/env python3
# run_audit.py
# ä¸€é”®é‡‡é›† SEO æ•°æ® + Lighthouse æ€§èƒ½æŒ‡æ ‡ â†’ ä¿å­˜ reports/raw.json

import argparse
import json
import subprocess
import sys
from pathlib import Path

from seo_audit_tool import audit

def fetch_lighthouse(url: str, timeout: int = 120) -> dict:
    cmd = (
        f'npx lighthouse "{url}" --quiet '
        '--chrome-flags="--headless" --output=json'
    )
    try:
        proc = subprocess.run(
            cmd,
            shell=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            encoding="utf-8",
            errors="ignore",
            timeout=timeout
        )
    except subprocess.TimeoutExpired:
        print("âš ï¸ Lighthouse æ‰§è¡Œè¶…æ—¶", file=sys.stderr)
        return {}

    if proc.returncode != 0:
        print("âš ï¸ Lighthouse æ‰§è¡Œå¤±è´¥ï¼Œstderr:", proc.stderr, file=sys.stderr)
        return {}

    raw = proc.stdout or ""
    try:
        data = json.loads(raw)
    except json.JSONDecodeError as e:
        print("âŒ JSON è§£æ Lighthouse è¾“å‡ºå¤±è´¥:", e, file=sys.stderr)
        return {}

    audits = data.get("audits", {})
    return {
        "lcp": audits.get("largest-contentful-paint", {}).get("numericValue", 0) / 1000,
        "inp": audits.get("interactive", {}).get("numericValue", 0),
        "cls": audits.get("cumulative-layout-shift", {}).get("numericValue", 0),
    }


def main():
    p = argparse.ArgumentParser(description="é‡‡é›† SEO æŠ¥å‘ŠåŸå§‹æ•°æ®")
    p.add_argument("url", help="è¦åˆ†æçš„ç›®æ ‡ URL")
    p.add_argument(
        "--no-render", action="store_true",
        help="ä»…é™æ€æŠ“å–ï¼Œä¸ä½¿ç”¨æµè§ˆå™¨æ¸²æŸ“"
    )
    p.add_argument(
        "--wait", type=int, default=3000,
        help="æ¸²æŸ“æ¨¡å¼ä¸‹ç­‰å¾…æ¯«ç§’æ•° (default: 3000)"
    )
    args = p.parse_args()

    url = args.url
    print(f"ğŸ” é‡‡é›† SEO åŸºç¡€æ•°æ®ï¼š{url}")
    rep = audit(url, render=not args.no_render, wait=args.wait)

    print("ğŸš€ å¼€å§‹ Lighthouse æ€§èƒ½æ£€æµ‹â€¦")
    perf = fetch_lighthouse(url)
    rep["perf"] = perf

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    out_dir = Path("reports")
    out_dir.mkdir(parents=True, exist_ok=True)

    # å†™å…¥ JSON
    raw_path = out_dir / "raw.json"
    with open(raw_path, "w", encoding="utf-8") as f:
        json.dump(rep, f, ensure_ascii=False, indent=2)
    print(f"âœ… é‡‡é›†å®Œæˆï¼ŒåŸå§‹æ•°æ®å·²ä¿å­˜è‡³ï¼š{raw_path}")

if __name__ == "__main__":
    main()

